{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObouYuoj9d45sNdONMEfFF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In this example, we will build a multi-label text classifier to predict the subject areas of arXiv papers from their abstract bodies. This type of classifier can be useful for conference submission portals like OpenReview. Given a paper abstract, the portal could provide suggestions for which areas the paper would best belong to.\n",
        "\n",
        "The dataset was collected using the arXiv Python library that provides a wrapper around the original arXiv API. Additionally, you can also find the dataset on Kaggle."
      ],
      "metadata": {
        "id": "EW0xOZmu54u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ast import literal_eval\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "c8pVgZEI5-Vd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "9Ckz6EGt8TQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data = pd.read_csv(\n",
        "    \"https://github.com/soumik12345/multi-label-text-classification/releases/download/v0.2/arxiv_data.csv\"\n",
        ")\n",
        "\n",
        "print(f\"There are {len(arxiv_data)} rows in the dataset.\")\n",
        "\n",
        "arxiv_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "3slsQh5m8s7s",
        "outputId": "7e4eb737-5235-4cf6-8710-8095362c5c40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 51774 rows in the dataset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59f717e9-419f-4d9e-a309-d45562203d0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59f717e9-419f-4d9e-a309-d45562203d0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59f717e9-419f-4d9e-a309-d45562203d0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59f717e9-419f-4d9e-a309-d45562203d0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove Duplicated records\n",
        "\n",
        "1. Remove row-level duplicates\n",
        "2. Remove records with same title"
      ],
      "metadata": {
        "id": "KAAQKkxp8tin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total duplicated entries : ', arxiv_data.shape[0] - arxiv_data.drop_duplicates().shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTguOzB19Imk",
        "outputId": "0cecfaf5-19cf-4bf6-bb79-0bbbfd87bbee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total duplicated entries :  12783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data = arxiv_data.drop_duplicates()\n",
        "print('Data volume after removing duplicates : ', arxiv_data.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdKr9Ryt9RZk",
        "outputId": "662448ea-1963-47c5-fe98-94ad5bdc34a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data volume after removing duplicates :  38991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data = arxiv_data[~arxiv_data[\"titles\"].duplicated()]\n",
        "print(f\"There are {len(arxiv_data)} rows in the final deduplicated dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOaviuFB9afH",
        "outputId": "c4ca7141-7541-474e-ee54-8b6179d7f400"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 38972 rows in the final deduplicated dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analyse terms"
      ],
      "metadata": {
        "id": "9STbSLTo-M9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data['terms'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0bGxclz92bb",
        "outputId": "b477cfa9-11e4-4ba3-dc6d-154ca960145a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"['cs.CV', 'cs.LG']\", \"['cs.CV', 'cs.AI', 'cs.LG']\",\n",
              "       \"['cs.CV', 'cs.AI']\", ..., \"['stat.ML', 'cs.LG', 'I.2.1; J.3']\",\n",
              "       \"['cs.LG', 'cs.NE', 'q-bio.BM', 'stat.ML']\",\n",
              "       \"['stat.ML', 'cs.CV', 'cs.LG', 'q-bio.QM']\"], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data['terms'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQKi5hYz-Qtb",
        "outputId": "b568a0b6-5fac-46d6-8630-b90f079ba6f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cs.CV']                                          12747\n",
              "['cs.LG', 'stat.ML']                                4074\n",
              "['cs.LG']                                           2046\n",
              "['cs.CV', 'cs.LG']                                  1486\n",
              "['cs.LG', 'cs.AI']                                  1206\n",
              "                                                   ...  \n",
              "['cs.LG', 'cs.CL', 'cs.HC', 'stat.ML']                 1\n",
              "['cs.LG', 'cs.AI', 'cs.CL', 'cs.PL', 'stat.ML']        1\n",
              "['cs.LG', 'cs.CL', 'stat.ME', 'stat.ML']               1\n",
              "['cs.LG', 'cs.CL', 'cs.LO', 'stat.ML']                 1\n",
              "['stat.ML', 'cs.CV', 'cs.LG', 'q-bio.QM']              1\n",
              "Name: terms, Length: 3157, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of 3157 distinct labels, 2321 labels occur only once. In order to better prepare the data for classification and the problem itself, we should remove these entries"
      ],
      "metadata": {
        "id": "eVBkoUqT-5wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data.groupby(\"terms\").filter(lambda x: len(x) == 1).shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM12dLRu-W6c",
        "outputId": "469babbc-2b05-4d2d-edf9-ac68c19c49e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2321"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the rare terms\n",
        "arxiv_data_filtered = arxiv_data.groupby(\"terms\").filter(lambda x: len(x) > 1)\n",
        "arxiv_data_filtered.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJrEUgVg_Ihy",
        "outputId": "258e50c3-3264-499a-c397-3729db4c5d93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36651, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the string labels to lists of strings\n",
        "The initial labels are represented as raw strings. Here we make them List[str] for a more compact representation."
      ],
      "metadata": {
        "id": "6RcyzFIS_LsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data_filtered[\"terms\"] = arxiv_data_filtered[\"terms\"].apply(\n",
        "    lambda x: literal_eval(x)\n",
        ")\n",
        "arxiv_data_filtered[\"terms\"].values[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bljr-Y6yHB_K",
        "outputId": "46352dbe-b255-4569-e587-bfa91d87dba1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['cs.CV', 'cs.LG']), list(['cs.CV', 'cs.AI', 'cs.LG']),\n",
              "       list(['cs.CV', 'cs.AI']), list(['cs.CV']),\n",
              "       list(['cs.CV', 'cs.LG'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use stratified splits because of class imbalance\n",
        "The dataset has a class imbalance problem. So, to have a fair evaluation result, we need to ensure the datasets are sampled with stratification."
      ],
      "metadata": {
        "id": "f-r1KDMAHEsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_split = 0.1\n",
        "\n",
        "# Initial train and test split\n",
        "train_df, test_df = train_test_split(\n",
        "    arxiv_data_filtered,\n",
        "    test_size=test_split,\n",
        "    stratify=arxiv_data_filtered[\"terms\"].values,\n",
        ")\n",
        "\n",
        "# Splitting the test set further into validation\n",
        "# and new test sets\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of rows in training set: {len(train_df)}\")\n",
        "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
        "print(f\"Number of rows in test set: {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjA8-5wJHLH7",
        "outputId": "e8614719-d830-4f7f-cfda-64aaec3c284f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in training set: 32985\n",
            "Number of rows in validation set: 1833\n",
            "Number of rows in test set: 1833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-label binarization\n",
        "Now we preprocess our labels using the StringLookup layer"
      ],
      "metadata": {
        "id": "Rg1SszLaHbWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = tf.ragged.constant(train_df[\"terms\"].values)\n",
        "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
        "lookup.adapt(terms)\n",
        "vocab = lookup.get_vocabulary()\n",
        "\n",
        "\n",
        "def invert_multi_hot(encoded_labels):\n",
        "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
        "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
        "    return np.take(vocab, hot_indices)\n",
        "\n",
        "\n",
        "print(\"Vocabulary:\\n\")\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhwbUgXQHo-x",
        "outputId": "e335d840-f0c1-464c-fc4e-1912056c5d44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "\n",
            "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.CR', 'math.OC', 'eess.SP', 'cs.GR', 'cs.SI', 'cs.MM', 'cs.SY', 'cs.IR', 'cs.MA', 'eess.SY', 'cs.HC', 'cs.DC', 'math.IT', 'cs.IT', 'cs.CY', 'stat.AP', 'stat.TH', 'math.ST', 'stat.ME', 'eess.AS', 'cs.SD', 'q-bio.QM', 'q-bio.NC', 'cs.DS', 'cs.GT', 'cs.CG', 'cs.NI', 'cs.SE', 'I.2.6', 'stat.CO', 'math.NA', 'cs.NA', 'physics.chem-ph', 'cs.DB', 'q-bio.BM', 'cs.LO', 'cond-mat.dis-nn', '68T45', 'math.PR', 'cs.PL', 'physics.comp-ph', 'I.2.10', 'cs.CE', 'cs.AR', 'q-fin.ST', 'cond-mat.stat-mech', 'quant-ph', 'math.DS', '68T05', 'physics.data-an', 'cs.CC', 'I.4.6', 'physics.soc-ph', 'physics.ao-ph', 'cs.DM', 'econ.EM', 'q-bio.GN', 'physics.med-ph', 'cs.PF', 'astro-ph.IM', 'I.4.8', 'math.AT', 'I.4', 'q-fin.TR', 'cs.FL', 'I.5.4', 'I.2', '68U10', 'physics.optics', 'hep-ex', '68T10', 'physics.geo-ph', 'cond-mat.mtrl-sci', 'physics.flu-dyn', 'math.AP', 'I.4; I.5', 'I.4.9', 'I.2.6; I.2.8', 'I.2.10; I.4; I.5', '68T01', '65D19', 'q-fin.CP', 'nlin.CD', 'math.CO', 'cs.MS', 'I.2.6; I.5.1', 'I.2.0; I.2.6', '68T07', 'cs.SC', 'cs.ET', 'K.3.2', 'I.2.8', 'I.2.10; I.4.8', '68U01', '68T30', '68', 'q-fin.GN', 'q-fin.EC', 'q-bio.MN', 'econ.GN', 'I.4.9; I.5.4', 'I.4.5', 'I.2; I.5', 'I.2; I.4; I.5', 'I.2.6; I.2.7', '68T99', '68Q32', '62H30', 'q-fin.RM', 'q-fin.PM', 'q-bio.TO', 'q-bio.OT', 'physics.bio-ph', 'nlin.AO', 'math.LO', 'math.FA', 'hep-ph', 'cond-mat.soft', 'I.4.6; I.4.8', 'I.4.4', 'I.4.3', 'I.4.0', 'I.2; J.2', 'I.2; I.2.6; I.2.7', 'I.2.7', 'I.2.6; I.5.4', 'I.2.6; I.2.9', 'I.2.6; I.2.7; H.3.1; H.3.3', 'I.2.6; I.2.10', 'I.2.6, I.5.4', 'I.2.1; J.3', 'I.2.10; I.5.1; I.4.8', 'I.2.10; I.4.8; I.5.4', 'I.2.10; I.2.6', 'I.2.1', 'H.3.1; I.2.6; I.2.7', 'H.3.1; H.3.3; I.2.6; I.2.7', 'G.3', 'F.2.2; I.2.7', 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3', '68Txx', '62H99', '62H35', '14J60 (Primary) 14F05, 14J26 (Secondary)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are separating the individual unique classes available from the label pool and then using this information to represent a given label set with 0's and 1's. Below is an example."
      ],
      "metadata": {
        "id": "tTNSm3KuIIdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_label = train_df[\"terms\"].iloc[10]\n",
        "print(f\"Original label: {sample_label}\")\n",
        "\n",
        "label_binarized = lookup([sample_label])\n",
        "print(f\"Label-binarized representation: {label_binarized}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLrc6EmUIX0R",
        "outputId": "9844df91-90fa-4e9a-debd-f49c784a8a82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label: ['cs.LG', 'cs.CL', 'cs.SE', 'stat.ML']\n",
            "Label-binarized representation: [[0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing and tf.data.Dataset objects\n",
        "We first get percentile estimates of the sequence lengths."
      ],
      "metadata": {
        "id": "CM_Mlmm9I88p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"summaries\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reb3ZKimJxOR",
        "outputId": "82c11e6a-3d5d-4d3c-b447-a05fc0957200"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    32985.000000\n",
              "mean       156.517235\n",
              "std         41.497190\n",
              "min          5.000000\n",
              "25%        128.000000\n",
              "50%        154.000000\n",
              "75%        183.000000\n",
              "max        462.000000\n",
              "Name: summaries, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that 50% of the abstracts have a length of 156. So, any number close to that value is a good enough approximate for the maximum sequence length.\n",
        "\n",
        "Now, we implement utilities to prepare our datasets."
      ],
      "metadata": {
        "id": "UEixo-m0JzEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seqlen = 150\n",
        "batch_size = 128\n",
        "padding_token = \"<pad>\"\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "\n",
        "def make_dataset(dataframe, is_train=True):\n",
        "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
        "    label_binarized = lookup(labels).numpy()\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dataframe[\"summaries\"].values, label_binarized)\n",
        "    )\n",
        "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "Nncv7fPLKB_m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can prepare the tf.data.Dataset objects."
      ],
      "metadata": {
        "id": "OkbGhGVDLLZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = make_dataset(train_df, is_train=True)\n",
        "validation_dataset = make_dataset(val_df, is_train=False)\n",
        "test_dataset = make_dataset(test_df, is_train=False)"
      ],
      "metadata": {
        "id": "JpWd0AhhLVAc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preview"
      ],
      "metadata": {
        "id": "qYWtSUlHLfPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "for i, text in enumerate(text_batch[:5]):\n",
        "    label = label_batch[i].numpy()[None, ...]\n",
        "    print(f\"Abstract: {text}\")\n",
        "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
        "    print(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0htOtsKLl2T",
        "outputId": "c85f201b-062a-4a39-e498-152efcaf5db3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract: b'The training of deep-learning-based 3D object detectors requires large\\ndatasets with 3D bounding box labels for supervision that have to be generated\\nby hand-labeling. We propose a network architecture and training procedure for\\nlearning monocular 3D object detection without 3D bounding box labels. By\\nrepresenting the objects as triangular meshes and employing differentiable\\nshape rendering, we define loss functions based on depth maps, segmentation\\nmasks, and ego- and object-motion, which are generated by pre-trained,\\noff-the-shelf networks. We evaluate the proposed algorithm on the real-world\\nKITTI dataset and achieve promising performance in comparison to\\nstate-of-the-art methods requiring 3D bounding box labels for training and\\nsuperior performance to conventional baseline methods.'\n",
            "Label(s): ['cs.CV']\n",
            " \n",
            "Abstract: b'Visual Domain Adaptation is a problem of immense importance in computer\\nvision. Previous approaches showcase the inability of even deep neural networks\\nto learn informative representations across domain shift. This problem is more\\nsevere for tasks where acquiring hand labeled data is extremely hard and\\ntedious. In this work, we focus on adapting the representations learned by\\nsegmentation networks across synthetic and real domains. Contrary to previous\\napproaches that use a simple adversarial objective or superpixel information to\\naid the process, we propose an approach based on Generative Adversarial\\nNetworks (GANs) that brings the embeddings closer in the learned feature space.\\nTo showcase the generality and scalability of our approach, we show that we can\\nachieve state of the art results on two challenging scenarios of synthetic to\\nreal domain adaptation. Additional exploratory experiments show that our\\napproach: (1) generalizes to unseen domains and (2) results in improved\\nalignment of source and target distributions.'\n",
            "Label(s): ['cs.CV' 'cs.LG' 'stat.ML']\n",
            " \n",
            "Abstract: b'Forecasts of product demand are essential for short- and long-term\\noptimization of logistics and production. Thus, the most accurate prediction\\npossible is desirable. In order to optimally train predictive models, the\\ndeviation of the forecast compared to the actual demand needs to be assessed by\\na proper metric. However, if a metric does not represent the actual prediction\\nerror, predictive models are insufficiently optimized and, consequently, will\\nyield inaccurate predictions. The most common metrics such as MAPE or RMSE,\\nhowever, are not suitable for the evaluation of forecasting errors, especially\\nfor lumpy and intermittent demand patterns, as they do not sufficiently account\\nfor, e.g., temporal shifts (prediction before or after actual demand) or\\ncost-related aspects. Therefore, we propose a novel metric that, in addition to\\nstatistical considerations, also addresses business aspects. Additionally, we\\nevaluate the metric based on simulated and real demand time series from the\\nautomotive aftermarket.'\n",
            "Label(s): ['cs.LG' 'stat.ML' 'q-fin.GN']\n",
            " \n",
            "Abstract: b'Zeroth-order (ZO, also known as derivative-free) methods, which estimate the\\ngradient only by two function evaluations, have attracted much attention\\nrecently because of its broad applications in machine learning community. The\\ntwo function evaluations are normally generated with random perturbations from\\nstandard Gaussian distribution. To speed up ZO methods, many methods, such as\\nvariance reduced stochastic ZO gradients and learning an adaptive Gaussian\\ndistribution, have recently been proposed to reduce the variances of ZO\\ngradients. However, it is still an open problem whether there is a space to\\nfurther improve the convergence of ZO methods. To explore this problem, in this\\npaper, we propose a new reinforcement learning based ZO algorithm (ZO-RL) with\\nlearning the sampling policy for generating the perturbations in ZO\\noptimization instead of using random sampling. To find the optimal policy, an\\nactor-critic RL algorithm called deep deterministic policy gradient (DDPG) with\\ntwo neural network function approximators is adopted. The learned sampling\\npolicy guides the perturbed points in the parameter space to estimate a more\\naccurate ZO gradient. To the best of our knowledge, our ZO-RL is the first\\nalgorithm to learn the sampling policy using reinforcement learning for ZO\\noptimization which is parallel to the existing methods. Especially, our ZO-RL\\ncan be combined with existing ZO algorithms that could further accelerate the\\nalgorithms. Experimental results for different ZO optimization problems show\\nthat our ZO-RL algorithm can effectively reduce the variances of ZO gradient by\\nlearning a sampling policy, and converge faster than existing ZO algorithms in\\ndifferent scenarios.'\n",
            "Label(s): ['cs.LG']\n",
            " \n",
            "Abstract: b'Machine learning models typically suffer from the domain shift problem when\\ntrained on a source dataset and evaluated on a target dataset of different\\ndistribution. To overcome this problem, domain generalisation (DG) methods aim\\nto leverage data from multiple source domains so that a trained model can\\ngeneralise to unseen domains. In this paper, we propose a novel DG approach\\nbased on \\\\emph{Deep Domain-Adversarial Image Generation} (DDAIG). Specifically,\\nDDAIG consists of three components, namely a label classifier, a domain\\nclassifier and a domain transformation network (DoTNet). The goal for DoTNet is\\nto map the source training data to unseen domains. This is achieved by having a\\nlearning objective formulated to ensure that the generated data can be\\ncorrectly classified by the label classifier while fooling the domain\\nclassifier. By augmenting the source training data with the generated unseen\\ndomain data, we can make the label classifier more robust to unknown domain\\nchanges. Extensive experiments on four DG datasets demonstrate the\\neffectiveness of our approach.'\n",
            "Label(s): ['cs.CV']\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization\n",
        "Before we feed the data to our model, we need to vectorize it (represent it in a numerical form). For that purpose, we will use the TextVectorization layer. It can operate as a part of your main model so that the model is excluded from the core preprocessing logic. This greatly reduces the chances of training / serving skew during inference.\n",
        "\n",
        "We first calculate the number of unique words present in the abstracts."
      ],
      "metadata": {
        "id": "Oyb1herjL_GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://stackoverflow.com/a/18937309/7636462\n",
        "vocabulary = set()\n",
        "train_df[\"summaries\"].str.lower().str.split().apply(vocabulary.update)\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUxKsjhOQVbV",
        "outputId": "a1d727a8-52e4-4750-dfc9-88cc9bd31bba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create our vectorization layer and map() to the tf.data.Datasets created earlier"
      ],
      "metadata": {
        "id": "4pq0nCVjRbr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
        ")"
      ],
      "metadata": {
        "id": "BaVLuRd2Rn8U"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`TextVectorization` layer needs to be adapted as per the vocabulary from our training set"
      ],
      "metadata": {
        "id": "9GtHvIVyToyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/CPU:0\"):\n",
        "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "test_dataset = test_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)"
      ],
      "metadata": {
        "id": "LaSBhmCyTw6K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A batch of raw text will first go through the TextVectorization layer and it will generate their integer representations. Internally, the TextVectorization layer will first create bi-grams out of the sequences and then represent them using TF-IDF. The output representations will then be passed to the shallow model responsible for text classification."
      ],
      "metadata": {
        "id": "8JuTl2xyUrGw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5VtIWCvXOt0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}