{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextTranslationWithAttention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMffpkNgfHOUcq1ILolvd/B"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Attention is all you need!\n",
        "\n",
        "This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation.\n",
        "\n",
        "While this architecture is somewhat outdated it is still a very useful project to work through to get a deeper understanding of attention mechanisms (before going on to Transformers).\n",
        "\n",
        "After training the model in this notebook, you will be able to input a Spanish sentence, such as \"¿todavia estan en casa?\", and return the English translation: \"are you still at home?\"\n",
        "\n",
        "The translation quality is reasonable for a toy example, but the generated attention plot is perhaps more interesting. This shows which parts of the input sentence has the model's attention while translating:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "b7Cg0sDV_fY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbsFpvHnAkrg",
        "outputId": "d95db445-74ef-4709-ffeb-ee2ccbf50cad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Collecting tensorflow<2.10,>=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (14.0.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.14.1)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.46.3)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.26.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 36.9 MB/s \n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-text-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "uqII_oanAco4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shape Checker\n",
        "\n",
        "In low-level API Codes, it's easy to get shapes wrong. Following class implements the check to ensure tensors are in proper shape as expected by the model"
      ],
      "metadata": {
        "id": "CH8bXaFLGgxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "Tr9HuOlkHERk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA and Data Preparation\n",
        "\n",
        "We'll use a language dataset provided by http://www.manythings.org/anki/ This dataset contains language translation pairs in the format:\n",
        "\n",
        "> May I borrow this book? ¿Puedo tomar prestado este libro?\n",
        "\n"
      ],
      "metadata": {
        "id": "iNcrpphsH0Sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset"
      ],
      "metadata": {
        "id": "oh0W2pPNJHnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file\n",
        "import pathlib\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFkziOWEH7Ii",
        "outputId": "c2083514-a23a-46e9-81d9-684cb1289897"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the dataset, here are the steps we'll take to prepare the data:\n",
        "\n",
        "* Add a start and end token to each sentence.\n",
        "* Clean the sentences by removing special characters.\n",
        "* Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "* Pad each sentence to a maximum length."
      ],
      "metadata": {
        "id": "BI-rL1j4JOv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  inp = [inp for targ, inp in pairs]\n",
        "  targ = [targ for targ, inp in pairs]\n",
        "\n",
        "  return targ, inp\n",
        "\n",
        "targ, inp = load_data(path_to_file)\n",
        "print(\"Example Input Sequence : \", inp[-1])\n",
        "print(\"Example Target Sequence : \", targ[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkEmoLo8JRyR",
        "outputId": "10e4efd4-579c-4f64-b25f-89295d8803e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Input Sequence :  Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
            "Example Target Sequence :  If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a TF Dataset\n",
        "\n",
        "From these arrays of strings you can create a tf.data.Dataset of strings that shuffles and batches them efficiently:\n",
        "\n",
        "From the [Doc](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) - \n",
        "\n",
        "> Randomly shuffles the elements of this dataset.\\\n",
        "  This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\\\n",
        "  For instance, if your dataset contains 10,000 elements but buffer_size is set to 1,000, then shuffle will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer."
      ],
      "metadata": {
        "id": "pYVMCMKUJygu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNy6voddMJtr",
        "outputId": "aae12da6-ce5e-4a8e-b790-c736ba4ea275"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Os toca a vosotros.' b'No volver\\xc3\\xa9 a tolerar tus errores.'\n",
            " b'\\xc2\\xbfTe gustar\\xc3\\xada beber algo?'\n",
            " b'Tom puso la mesa para cenar mientras Mary cocinaba.'\n",
            " b'La manera en que ella nos habl\\xc3\\xb3 fue sospechosa.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b\"Now, it's your turn.\" b\"I won't tolerate your mistakes again.\"\n",
            " b'Would you like to drink anything?'\n",
            " b'Tom set the table for dinner while Mary cooked.'\n",
            " b'The way she spoke to us was suspicious.'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text preprocessing\n",
        "\n",
        "`Standardization`\n",
        "\n",
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The tensorflow_text package contains a unicode normalize operation:"
      ],
      "metadata": {
        "id": "knm15F0VNZhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tf.constant('¿Todavía está en casa?')\n",
        "\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrFezFIIN9T_",
        "outputId": "c1c89d63-220e-48aa-9625-71cc5d7542af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
            "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZhTF_BAOITA",
        "outputId": "7340282b-e2f6-4dba-a105-ad08aa466d22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Todavía está en casa?\n",
            "[START] ¿ todavia esta en casa ? [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "This standardization function will be wrapped up in a tf.keras.layers.TextVectorization layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ],
      "metadata": {
        "id": "UK7Po5LrOmHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ],
      "metadata": {
        "id": "Sdkos6tyO5Fi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to adapt the Vectorization layer to the input and target sequences\n",
        "\n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r67VnQTFPCYV",
        "outputId": "814620ca-2f6c-4e58-c2c6-092ed4d95d9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wxr7vZOPtlI",
        "outputId": "b2a3ac4d-2466-4b67-d30f-4e7acb35c81e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ],
      "metadata": {
        "id": "0OHWbdLjP2zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcu6agoKQGtd",
        "outputId": "178f920e-3c6c-4723-becf-d3eedb8052a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[   2,  441,  994,    8,  893,    4,    3,    0,    0,    0],\n",
              "       [   2,    9, 1007,    8,    1,  183,  672,    4,    3,    0],\n",
              "       [   2,   13,   30,  167,  545,   57,   12,    3,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The get_vocabulary method can be used to convert token IDs back to text:"
      ],
      "metadata": {
        "id": "JnwI1sbwQyzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wrJ6eZVYQzz9",
        "outputId": "55fe3213-efad-4330-c8aa-754d9a469a29"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] os toca a vosotros . [END]           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "rmv_gt4YRZmT",
        "outputId": "64c0cc6c-cbe4-4ac6-f52a-d2d4db76a7a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lq5EUGmnSqBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}